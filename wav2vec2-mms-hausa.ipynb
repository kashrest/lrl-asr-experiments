{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb385bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric, load_dataset, Audio\n",
    "from transformers import Wav2Vec2ForCTC, AutoProcessor, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "from finetuning_util_hausa import preprocess_texts, preprocess_text, create_vocab_dict, create_data_collator, compute_metrics, ASRDataset\n",
    "\n",
    "import json\n",
    "\n",
    "cache_dir_fleurs =\"/data/users/kashrest/lrl-asr-experiments/data/fleurs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hausa\n",
    "cache_dir=\"/data/users/kashrest/lrl-asr-experiments/data/fleurs\"\n",
    "stream_data = load_dataset(\"google/fleurs\", \"ha_ng\", split=\"test\", cache_dir=cache_dir, streaming=True)\n",
    "sample = next(iter(stream_data))\n",
    "print(sample)\n",
    "ha_sample = sample[\"audio\"][\"array\"]\n",
    "ha_sample_transcription = sample[\"transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hausa\n",
    "\"\"\"from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\"\"\"\n",
    "\n",
    "cache_dir=\"/data/users/kashrest/lrl-asr-experiments/data/fleurs\"\n",
    "\n",
    "data = load_dataset(\"google/fleurs\", \"ha_ng\", split=\"test\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04d2c6",
   "metadata": {},
   "source": [
    "# Finetuning - MMS-1b-all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d6eb5",
   "metadata": {},
   "source": [
    "## Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd15a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fleurs_hausa_train_transcriptions = []\n",
    "fleurs_hausa_train_audio= []\n",
    "\n",
    "fleurs_hausa_val_transcriptions = []\n",
    "fleurs_hausa_val_audio= []\n",
    "\n",
    "fleurs_hausa_test_transcriptions = []\n",
    "fleurs_hausa_test_audio= []\n",
    "\n",
    "for elem in load_dataset(\"google/fleurs\", \"ha_ng\", split=\"train\", cache_dir=cache_dir_fleurs):\n",
    "    fleurs_hausa_train_transcriptions.append(elem[\"raw_transcription\"])\n",
    "    fleurs_hausa_train_audio.append(elem[\"audio\"][\"array\"])\n",
    "    \n",
    "for elem in load_dataset(\"google/fleurs\", \"ha_ng\", split=\"validation\", cache_dir=cache_dir_fleurs):\n",
    "    fleurs_hausa_val_transcriptions.append(elem[\"raw_transcription\"])\n",
    "    fleurs_hausa_val_audio.append(elem[\"audio\"][\"array\"])\n",
    "    \n",
    "for elem in load_dataset(\"google/fleurs\", \"ha_ng\", split=\"test\", cache_dir=cache_dir_fleurs):\n",
    "    fleurs_hausa_test_transcriptions.append(elem[\"raw_transcription\"])\n",
    "    fleurs_hausa_test_audio.append(elem[\"audio\"][\"array\"])\n",
    "\n",
    "fleurs_hausa_train_transcriptions = preprocess_texts(fleurs_hausa_train_transcriptions)\n",
    "fleurs_hausa_val_transcriptions = preprocess_texts(fleurs_hausa_val_transcriptions)\n",
    "fleurs_hausa_test_transcriptions = preprocess_texts(fleurs_hausa_test_transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO-639-3 for Hausa = \"hau\"\n",
    "vocab_dict = create_vocab_dict(fleurs_hausa_train_transcriptions, fleurs_hausa_val_transcriptions, fleurs_hausa_test_transcriptions)\n",
    "target_lang = \"hau\"\n",
    "new_vocab_dict = {target_lang: vocab_dict}\n",
    "root = \"/data/users/kashrest/lrl-asr-experiments/\"\n",
    "out_dir = \"facebook_mms-1b-all/poc-1/\"\n",
    "try:\n",
    "    os.mkdir(out_dir)\n",
    "except:\n",
    "    print(f\"Experiment folder already exists\") \n",
    "    \n",
    "with open(root+out_dir+'vocab.json', 'w+') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(root+out_dir, unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "model_sampling_rate = 16000\n",
    "\n",
    "train_dataset = ASRDataset(fleurs_hausa_train_audio, fleurs_hausa_train_transcriptions, model_sampling_rate, processor)\n",
    "val_dataset = ASRDataset(fleurs_hausa_val_audio, fleurs_hausa_val_transcriptions, model_sampling_rate, processor)\n",
    "test_dataset = ASRDataset(fleurs_hausa_test_audio, fleurs_hausa_test_transcriptions, model_sampling_rate, processor)\n",
    "\n",
    "data_collator = create_data_collator(processor)\n",
    "\n",
    "model_id = \"facebook/mms-1b-all\"\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    model_id,\n",
    "    attention_dropout=0.0,\n",
    "    hidden_dropout=0.0,\n",
    "    feat_proj_dropout=0.0,\n",
    "    layerdrop=0.0,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb601149",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_adapter_layers()\n",
    "\n",
    "model.freeze_base_model()\n",
    "\n",
    "adapter_weights = model._get_adapters()\n",
    "for param in adapter_weights.values():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=root+out_dir,\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=4,\n",
    "  gradient_checkpointing=True,\n",
    "  fp16=True,\n",
    "  save_steps=200,\n",
    "  eval_steps=100,\n",
    "  logging_steps=100,\n",
    "  learning_rate=2e-4,\n",
    "  warmup_steps=100,\n",
    "  save_total_limit=2,\n",
    "  push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb4bee",
   "metadata": {},
   "source": [
    "## Evaluation of fine-tuned checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"facebook/mms-1b\"\n",
    "best_model_checkpoint = \"./facebook_mms-1b/hausa-finetuning-2-script-basic-example/checkpoint-5200/\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
    "#processor.tokenizer.get_vocab()[\"hau\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _basic_preprocessing(transcription):\n",
    "    chars_to_ignore = [\",\", \"?\", \".\", \"!\", \"-\", \";\", \":\", \"\\\\\", '\"', '“',\"%\", \"‘\", '”', \"�\"]\n",
    "    chars_to_ignore_regex = (f'[{\"\".join(chars_to_ignore)}]' if chars_to_ignore is not None else None)\n",
    "    transcription = re.sub(chars_to_ignore_regex, \"\", transcription.lower())\n",
    "    return transcription\n",
    "    \n",
    "processor.tokenizer.set_target_lang(\"hau\")\n",
    "#model.load_adapter(\"hau\")\n",
    "transcriptions = []\n",
    "gold_transcriptions = []\n",
    "for elem in tqdm(data):\n",
    "    inputs = processor(elem[\"audio\"][\"array\"], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    ids = torch.argmax(outputs, dim=-1)[0]\n",
    "    transcriptions.append(processor.decode(ids))\n",
    "    gold_transcriptions.append(_basic_preprocessing(elem[\"transcription\"]))\n",
    "    # 'wachambuzi wa soka wanamtaja mesi kama nyota hatari zaidi duniani'\n",
    "    # => In English: \"soccer analysts describe Messi as the most dangerous player in the world\"\n",
    "    \n",
    "with open(\"./facebook_mms-1b/hausa-finetuning-2-script-basic-example/fluers_test_output.jsonl\", \"w\") as f:\n",
    "    for transcription in transcriptions:\n",
    "        json.dump(transcription, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08383ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./facebook_mms-1b/hausa-finetuning-2-script-basic-example/fluers_test_output.jsonl\", \"w\") as f:\n",
    "    for transcription in transcriptions:\n",
    "        json.dump(transcription, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")\n",
    "wer = wer_metric.compute(predictions=transcriptions, references=gold_transcriptions)\n",
    "cer = cer_metric.compute(predictions=transcriptions, references=gold_transcriptions)\n",
    "wer, cer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e5439",
   "metadata": {},
   "source": [
    "# Inference - MMS-1b-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba590f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"facebook/mms-1b-all\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.get_vocab()[\"hau\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = processor.pad(input_features, padding=self.padding, max_length=self.max_length, pad_to_multiple_of=self.pad_to_multiple_of, return_tensors=\"pt\")\n",
    "processor.tokenizer.set_target_lang(\"hau\")\n",
    "model.load_adapter(\"hau\")\n",
    "transcriptions = []\n",
    "gold_transcriptions = []\n",
    "for elem in tqdm(data):\n",
    "    inputs = processor(elem[\"audio\"][\"array\"], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    ids = torch.argmax(outputs, dim=-1)[0]\n",
    "    transcriptions.append(processor.decode(ids))\n",
    "    gold_transcriptions.append(preprocess_text(elem[\"raw_transcription\"]))\n",
    "    # 'wachambuzi wa soka wanamtaja mesi kama nyota hatari zaidi duniani'\n",
    "    # => In English: \"soccer analysts describe Messi as the most dangerous player in the world\"\n",
    "    \n",
    "with open(\"facebook_mms-1b-all/zero-shot/fluers_customized_preprocessing_test_output.jsonl\", \"w\") as f:\n",
    "    for transcription in transcriptions:\n",
    "        json.dump(transcription, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcriptions), len(gold_transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b00062",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")\n",
    "wer = wer_metric.compute(predictions=transcriptions, references=gold_transcriptions)\n",
    "cer = cer_metric.compute(predictions=transcriptions, references=gold_transcriptions)\n",
    "wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65028c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba636fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_transcriptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a9823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
