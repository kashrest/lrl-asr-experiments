{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1dd1ccd-fe75-4ca1-bfe5-c0938c6655ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom ASR dataset for Hausa made from combination of FLEURS, Common Voice, and BibleTTS.\n",
    "\n",
    "Example of a custom_dataset function, for Hausa. You must have a generate_dataset() function that returns a dataset with train/validation/test split.\n",
    "\"\"\"\n",
    "from typing import Dict, List\n",
    "import os\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "def generate_dataset() -> Dict[str, Dict[str, List]]:\n",
    "    cache_dir_fleurs = \"/data/users/kashrest/lrl-asr-experiments/data/fleurs\"\n",
    "    cache_dir_cv_13 = cache_dir=\"/data/users/kashrest/lrl-asr-experiments/data/cv_13\"\n",
    "\n",
    "    fleurs_hausa_train = load_dataset(\"google/fleurs\", \"ha_ng\", split=\"train\", cache_dir=cache_dir_fleurs)\n",
    "    fleurs_hausa_val = load_dataset(\"google/fleurs\", \"ha_ng\", split=\"validation\", cache_dir=cache_dir_fleurs)\n",
    "    fleurs_hausa_test = load_dataset(\"google/fleurs\", \"ha_ng\", split=\"test\", cache_dir=cache_dir_fleurs)\n",
    "\n",
    "    cv_hausa_train, cv_hausa_val, cv_hausa_test = None, None, None\n",
    "    bible_train_hausa_transcription_paths, bible_val_hausa_transcription_paths, bible_test_hausa_transcription_paths = None, None, None\n",
    "    bible_train_hausa_audio_paths, bible_val_hausa_audio_paths, bible_test_hausa_audio_paths = None, None, None\n",
    "\n",
    "    cv_hausa_train = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"ha\", split=\"train\", cache_dir=cache_dir_cv_13)\n",
    "    cv_hausa_val = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"ha\", split=\"validation\", cache_dir=cache_dir_cv_13)\n",
    "    cv_hausa_test = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"ha\", split=\"test\", cache_dir=cache_dir_cv_13)\n",
    "\n",
    "    cv_hausa_train = cv_hausa_train.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "    cv_hausa_val = cv_hausa_val.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "    cv_hausa_test = cv_hausa_test.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "    bible_train_hausa_transcription_paths = []\n",
    "    bible_train_hausa_audio_paths = []\n",
    "\n",
    "    bible_val_hausa_transcription_paths = []\n",
    "    bible_val_hausa_audio_paths = []\n",
    "\n",
    "    bible_test_hausa_transcription_paths = []\n",
    "    bible_test_hausa_audio_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\"../data/open_slr_129/hausa/train\"):\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                if file[-3:] == \"txt\":\n",
    "                    bible_train_hausa_transcription_paths.append(root+\"/\"+file)\n",
    "                elif file [-4:] == \"flac\":\n",
    "                    bible_train_hausa_audio_paths.append(root+\"/\"+file)\n",
    "\n",
    "    for root, dirs, files in os.walk(\"../data/open_slr_129/hausa/dev\"):\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                if file[-3:] == \"txt\":\n",
    "                    bible_val_hausa_transcription_paths.append(root+\"/\"+file)\n",
    "                elif file [-4:] == \"flac\":\n",
    "                    bible_val_hausa_audio_paths.append(root+\"/\"+file)\n",
    "\n",
    "    for root, dirs, files in os.walk(\"../data/open_slr_129/hausa/test\"):\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                if file[-3:] == \"txt\":\n",
    "                    bible_test_hausa_transcription_paths.append(root+\"/\"+file)\n",
    "                elif file [-4:] == \"flac\":\n",
    "                    bible_test_hausa_audio_paths.append(root+\"/\"+file)\n",
    "\n",
    "    model_sampling_rate = 16000\n",
    "\n",
    "    train_audio_hausa = []\n",
    "    train_transcriptions_hausa = []\n",
    "\n",
    "    for elem in fleurs_hausa_train:\n",
    "        assert elem[\"audio\"][\"sampling_rate\"] == model_sampling_rate\n",
    "        train_audio_hausa.append(elem[\"audio\"][\"array\"])\n",
    "        train_transcriptions_hausa.append(elem[\"raw_transcription\"])\n",
    "\n",
    "    for elem in cv_hausa_train:\n",
    "        assert elem[\"audio\"][\"sampling_rate\"] == model_sampling_rate\n",
    "        train_audio_hausa.append(elem[\"audio\"][\"array\"])\n",
    "        train_transcriptions_hausa.append(elem[\"sentence\"])\n",
    "\n",
    "    for audio_file, transcription_file in zip(sorted(bible_train_hausa_audio_paths), sorted(bible_train_hausa_transcription_paths)):\n",
    "        assert audio_file[:-5] == transcription_file[:-4]\n",
    "        with open(transcription_file, \"r\") as f:\n",
    "            transcript = f.readline()\n",
    "            train_transcriptions_hausa.append(transcript)\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        resampler = T.Resample(sample_rate, model_sampling_rate, dtype=waveform.dtype)\n",
    "        resampled_waveform = resampler(waveform)\n",
    "        train_audio_hausa.append(resampled_waveform[0].numpy())\n",
    "\n",
    "    val_audio_hausa = []\n",
    "    val_transcriptions_hausa = []\n",
    "\n",
    "    for elem in fleurs_hausa_val:\n",
    "        assert elem[\"audio\"][\"sampling_rate\"] == model_sampling_rate\n",
    "        val_audio_hausa.append(elem[\"audio\"][\"array\"])\n",
    "        val_transcriptions_hausa.append(elem[\"raw_transcription\"])\n",
    "\n",
    "    for elem in cv_hausa_val:\n",
    "        assert elem[\"audio\"][\"sampling_rate\"] == model_sampling_rate\n",
    "        val_audio_hausa.append(elem[\"audio\"][\"array\"])\n",
    "\n",
    "        val_transcriptions_hausa.append(elem[\"sentence\"])\n",
    "\n",
    "    for audio_file, transcription_file in zip(sorted(bible_val_hausa_audio_paths), sorted(bible_val_hausa_transcription_paths)):\n",
    "        assert audio_file[:-5] == transcription_file[:-4]\n",
    "        with open(transcription_file, \"r\") as f:\n",
    "            transcript = f.readline()\n",
    "            val_transcriptions_hausa.append(transcript)\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        resampler = T.Resample(sample_rate, model_sampling_rate, dtype=waveform.dtype)\n",
    "        resampled_waveform = resampler(waveform)\n",
    "        val_audio_hausa.append(resampled_waveform[0].numpy())\n",
    "\n",
    "    test_audio_hausa = []\n",
    "    test_transcriptions_hausa = []\n",
    "\n",
    "    for elem in fleurs_hausa_val:\n",
    "        assert elem[\"audio\"][\"sampling_rate\"] == model_sampling_rate\n",
    "        test_audio_hausa.append(elem[\"audio\"][\"array\"])\n",
    "        test_transcriptions_hausa.append(elem[\"raw_transcription\"])\n",
    "\n",
    "    for elem in cv_hausa_test:\n",
    "        assert elem[\"audio\"][\"sampling_rate\"] == model_sampling_rate\n",
    "        test_audio_hausa.append(elem[\"audio\"][\"array\"])\n",
    "        test_transcriptions_hausa.append(elem[\"sentence\"])\n",
    "\n",
    "    for audio_file, transcription_file in zip(sorted(bible_test_hausa_audio_paths), sorted(bible_test_hausa_transcription_paths)):\n",
    "        assert audio_file[:-5] == transcription_file[:-4]\n",
    "        with open(transcription_file, \"r\") as f:\n",
    "            transcript = f.readline()\n",
    "            test_transcriptions_hausa.append(transcript)\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        resampler = T.Resample(sample_rate, model_sampling_rate, dtype=waveform.dtype)\n",
    "        resampled_waveform = resampler(waveform)\n",
    "        test_audio_hausa.append(resampled_waveform[0].numpy())\n",
    "        \n",
    "    return {\"train\": {\"audio\": train_audio_hausa, \"transcriptions\": train_transcriptions_hausa}, \"validation\": {\"audio\": val_audio_hausa, \"transcriptions\": val_transcriptions_hausa}, \"test\": {\"audio\": test_audio_hausa, \"transcriptions\": test_transcriptions_hausa}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6def40f-c955-403d-9b09-b47d5938fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dad896-5853-42b6-b5b1-a6a2166777b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d[\"train\"][\"transcriptions\"]), len(d[\"validation\"][\"transcriptions\"]), len(d[\"test\"][\"transcriptions\"]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f39a55-7fcb-4c2b-b341-bc70e6de6c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
